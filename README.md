This is a Transformer model that generates human-like musical dynamics given a MIDI file. In other words, it performs music like a human!

<img width="468" alt="Model Architecture" src="https://github.com/user-attachments/assets/37003f9a-9442-4682-aec9-83c7abddcc62">

See [StyleNet](https://github.com/imalikshake/StyleNet) or [MIDI-DDSP](https://github.com/magenta/midi-ddsp) for similar projects.

If you wish to learn more, please check out the [Auto-Dynamics](https://grace4x.github.io/auto-dynamics-siste) site

# Dataset
The dataset used is [MAESTRO V3.0.0](https://magenta.tensorflow.org/datasets/maestro) under a [Creative Commons license](https://creativecommons.org/licenses/by-nc-sa/4.0/).
